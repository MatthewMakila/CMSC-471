{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56b4284",
   "metadata": {},
   "source": [
    "# Matthew Makila: HW 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c4d99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import numpy as nump\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255addb",
   "metadata": {},
   "source": [
    "### File import functions for the 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8682d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_import(f_name):    # for mileage data\n",
    "    # specify features and the response var for file extraction and storage as a table\n",
    "    feat_names = ['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
    "    f_feat_names = ['x0', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
    "    df = pd.read_csv(f_name, usecols=feat_names)\n",
    "    resp_vect = df['mpg'].values.tolist()\n",
    "\n",
    "    # scale the features\n",
    "    scale_df = ((df - df.mean()) / df.std())\n",
    "\n",
    "    # add vector for x0 of 1's; remove the response var\n",
    "    x_0 = []\n",
    "    for i in range(len(resp_vect)): x_0.append(1)\n",
    "    scale_df = scale_df.drop('mpg', axis='columns')\n",
    "    scale_df.insert(0, \"x0\", x_0, True)\n",
    "\n",
    "    # create feature matrix to store all scaled features\n",
    "    feat_matrix = []\n",
    "    for feat in f_feat_names:\n",
    "        feat_matrix.append(scale_df[feat].values.tolist())\n",
    "    return feat_matrix, resp_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "374647a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_import2(f_name):   # for cancer data\n",
    "    df = pd.read_csv(f_name)\n",
    "    resp_vect = df['LungCancer'].values.tolist()\n",
    "    # add vector for x0 of 1's; remove the response var\n",
    "    x_0 = []\n",
    "    for i in range(len(resp_vect)): x_0.append(1)\n",
    "    df = df.drop('LungCancer', axis='columns')\n",
    "    df.insert(0, \"x0\", x_0, True)\n",
    "    feat_names = ['x0', 'Smoking']\n",
    "    feat_mat = df.values.tolist()\n",
    "\n",
    "    return feat_mat, resp_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1278fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_import3(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    X = df.iloc[:, 1:].copy()\n",
    "    # X = (X - X.mean()) / X.std()\n",
    "    X['x0'] = 1\n",
    "    cols = X.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    X = X[cols]\n",
    "\n",
    "    X = nump.matrix(X)\n",
    "    y = nump.transpose(nump.matrix(df['Species']))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20a770",
   "metadata": {},
   "source": [
    "### Gradient Descent Function for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7566d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, alpha, model):\n",
    "    # create vector to hold the theta values (past and present), initialize our theta vectors to 0\n",
    "    start = time.time()\n",
    "    runtime = 0\n",
    "    iteration_list = []\n",
    "    iterations = 0\n",
    "    threshold = 0.00001\n",
    "    m = len(y)  # number of observations\n",
    "    thetas = []\n",
    "    old_thetas = []\n",
    "    diff_vect = []\n",
    "    costs = []\n",
    "    if model == 'linear':\n",
    "        for i in range(len(X)):\n",
    "            thetas.append(0)\n",
    "            old_thetas.append(0)\n",
    "            diff_vect.append(0)\n",
    "    else:\n",
    "        thetas = nump.zeros(len(X[0]))\n",
    "        old_thetas = nump.zeros(len(X[0]))\n",
    "        diff_vect = nump.zeros(len(X[0]))\n",
    "    not_converged = True\n",
    "    true_count = 0\n",
    "    while not_converged:\n",
    "        # loop over GDA equation algorithm\n",
    "        for j in range(len(thetas)):    # loop to update each feature\n",
    "            g_sum = 0\n",
    "            for i in range(m):  # loop to compute each summation over all observations\n",
    "                h_theta_x = 0\n",
    "                if model == 'linear':\n",
    "                    for n in range(len(thetas)):\n",
    "                        h_theta_x += (old_thetas[n] * X[n][i])\n",
    "                elif model == 'cancer':\n",
    "                    p = -1 * (nump.dot(old_thetas, nump.array(X[i])))\n",
    "                    h_theta_x = (1 / (1 + math.exp(p)))\n",
    "                else:\n",
    "                    p = -1 * (nump.dot(old_thetas, X[i]))\n",
    "                    h_theta_x = (1 / (1 + math.exp(p)))\n",
    "                if model == 'linear':\n",
    "                    g_sum += (X[j][i] * (h_theta_x - y[i]))\n",
    "                else:\n",
    "                    g_sum += (X[i][j] * (h_theta_x - y[i]))\n",
    "            # add back to new theta here\n",
    "            thetas[j] = old_thetas[j] - (alpha / m) * g_sum\n",
    "        # check differences of new thetas will old thetas & check threshold\n",
    "        for i in range(len(thetas)):\n",
    "            diff_vect[i] = abs(thetas[i] - old_thetas[i])\n",
    "            if diff_vect[i] < threshold:\n",
    "                true_count += 1\n",
    "\n",
    "        # if all differences are less than threshold, we converged\n",
    "        if true_count == len(diff_vect):\n",
    "            not_converged = False\n",
    "            end = time.time()\n",
    "            runtime = end-start\n",
    "        else:\n",
    "            # update old thetas to continue GDA next iteration\n",
    "            true_count = 0\n",
    "            for i in range(len(thetas)):\n",
    "                old_thetas[i] = thetas[i]\n",
    "    return thetas, runtime, costs, iteration_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c93d0",
   "metadata": {},
   "source": [
    "### Helper functions to solve Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e02c3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpg_estimate(X, y, Theta):\n",
    "    # create a vector of estimations (y hat)\n",
    "    y_hat = []\n",
    "    theta = nump.array(Theta)\n",
    "    for i in range(len(y)):\n",
    "        sample = []\n",
    "        for j in range(len(X)):\n",
    "            sample.append(X[j][i])\n",
    "        # calculate a y hat with numpy: multiply theta transpose by that sample's features\n",
    "        new_X = nump.array(sample)\n",
    "        y_hat.append(nump.dot(theta, new_X))\n",
    "    # calculate the error between observed and predicted\n",
    "    calc_errors(y, y_hat, X)\n",
    "\n",
    "\n",
    "def calc_errors(y, y_hat, X):\n",
    "    error = nump.array(y) - nump.array(y_hat).T\n",
    "    data = {'Observed mileage': y, 'Estimated mileage': y_hat, 'Error': error}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    print(df)\n",
    "    # calculate R^2 and adjusted R^2\n",
    "    SSR = pow(error, 2)\n",
    "    SST = pow((nump.array(y) - nump.array(nump.mean(y)).T), 2)\n",
    "    R_Sq = 1 - (sum(SSR) / sum(SST))\n",
    "    A_R_Sq = 1 - (1 - R_Sq) * ((len(y) - 1) / (len(y) - len(X)))\n",
    "    print(\"R-Squared: \", R_Sq)\n",
    "    print(\"Adjusted R-Squared: \", A_R_Sq)\n",
    "\n",
    "\n",
    "def LOOCV(X, y, alpha, model):\n",
    "    m = len(y)\n",
    "    n = len(X)\n",
    "    y_hat = []\n",
    "    for i in range(m):\n",
    "        # remember original intact matrices for X and y while we remove 1 at a time\n",
    "        n_X = copy.deepcopy(X)\n",
    "        n_y = copy.deepcopy(y)\n",
    "        # begin removals\n",
    "        feat_to_predict = []\n",
    "        n_y.pop(i)\n",
    "        for j in range(n):  # save & remove all features of a specific example to predict later\n",
    "            feat_to_predict.append(n_X[j][i])\n",
    "            n_X[j].pop(i)\n",
    "\n",
    "        theta, run, cost, it = gradient_descent(n_X, n_y, alpha, 'linear')   # with 1 left out\n",
    "        y_hat.append(nump.dot(theta, feat_to_predict))\n",
    "    calc_errors(y, y_hat, X)\n",
    "\n",
    "    \n",
    "def k_calc_errors(y, y_hat, X):\n",
    "    Rs = []\n",
    "    A_Rs = []\n",
    "    for i in range(len(X) - 1):\n",
    "        error = nump.array(y) - nump.array(y_hat[i]).T\n",
    "        # calculate R^2 and adjusted R^2\n",
    "        SSR = sum(pow(error, 2))\n",
    "        SST = sum(pow((nump.array(y) - nump.array(nump.mean(y)).T), 2))\n",
    "        R_Sq = 1 - (SSR / SST)\n",
    "        A_R_Sq = 1 - (1 - R_Sq) * ((len(y) - 1) / (len(y) - len(X)))\n",
    "        Rs.append(R_Sq)\n",
    "        A_Rs.append(A_R_Sq)\n",
    "    plot_rs(Rs, A_Rs)\n",
    "    \n",
    "    \n",
    "def k_feat_calc(X, y, alpha):\n",
    "    y_hat = []\n",
    "    n = len(X)\n",
    "    for i in range(n + 1):\n",
    "        theta, run, cost, it = gradient_descent(X[:i + 1], y, alpha, 'linear')  # with 1 left out\n",
    "        y_hat.append(nump.dot(theta, X[:i + 1]))\n",
    "    y_hat.pop(0)    # destroy first set\n",
    "    k_calc_errors(y, y_hat, X)\n",
    "    \n",
    "\n",
    "def plot_rs(R, A_R):\n",
    "    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    plt.plot(x, R, label='R-Squared')\n",
    "    plt.plot(x, A_R, label='Adjusted R-Squared')\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"R-Squared Values\")\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2af21a",
   "metadata": {},
   "source": [
    "### 1. (A) (Predict car mileage using MLR, report errors, and report R-squared values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "453f3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Observed mileage  Estimated mileage     Error\n",
      "0               21.0          22.598999 -1.598999\n",
      "1               21.0          22.111664 -1.111664\n",
      "2               22.8          26.251209 -3.451209\n",
      "3               21.4          21.236887  0.163113\n",
      "4               18.7          17.692871  1.007129\n",
      "5               18.1          20.383144 -2.283144\n",
      "6               14.3          14.385650 -0.085650\n",
      "7               24.4          22.495915  1.904085\n",
      "8               22.8          24.418683 -1.618683\n",
      "9               19.2          18.699417  0.500583\n",
      "10              17.8          19.191877 -1.391877\n",
      "11              16.4          14.173373  2.226627\n",
      "12              17.3          15.600147  1.699853\n",
      "13              15.2          15.742774 -0.542774\n",
      "14              10.4          12.033212 -1.633212\n",
      "15              10.4          10.936323 -0.536323\n",
      "16              14.7          10.494081  4.205919\n",
      "17              32.4          27.773308  4.626692\n",
      "18              30.4          29.895863  0.504137\n",
      "19              33.9          29.512193  4.387807\n",
      "20              21.5          23.643007 -2.143007\n",
      "21              15.5          16.942991 -1.442991\n",
      "22              15.2          17.732225 -2.532225\n",
      "23              13.3          13.306338 -0.006338\n",
      "24              19.2          16.691084  2.508916\n",
      "25              27.3          28.293566 -0.993566\n",
      "26              26.0          26.153332 -0.153332\n",
      "27              30.4          27.635962  2.764038\n",
      "28              15.8          18.870443 -3.070443\n",
      "29              19.7          19.693665  0.006335\n",
      "30              15.0          13.940834  1.059166\n",
      "31              21.4          24.368962 -2.968962\n",
      "R-Squared:  0.8690157579509393\n",
      "Adjusted R-Squared:  0.8066423093561486\n"
     ]
    }
   ],
   "source": [
    "X_, y_ = file_import('mileage.csv')\n",
    "a = 0.2\n",
    "\"\"\"1\"\"\"\n",
    "# 1A\n",
    "Thetas, runtime, costs, iterations = gradient_descent(X_, y_, a, 'linear')\n",
    "mpg_estimate(X_, y_, Thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0006c1a",
   "metadata": {},
   "source": [
    "##### We can see in this portion that the R-squared and adjusted R-squared values are relatively high (both higher than 0.8) and that the errors between observations are not ever more/less than 5 mpg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6517ac4",
   "metadata": {},
   "source": [
    "### 1. (B) (Predict car mileage using LOOCV with MLR, report errors, and report R-squared values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38710d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Observed mileage  Estimated mileage     Error\n",
      "0               21.0          23.292471 -2.292471\n",
      "1               21.0          22.566202 -1.566202\n",
      "2               22.8          27.334015 -4.534015\n",
      "3               21.4          21.188796  0.211204\n",
      "4               18.7          17.441872  1.258128\n",
      "5               18.1          21.281126 -3.181126\n",
      "6               14.3          14.426968 -0.126968\n",
      "7               24.4          21.557089  2.842911\n",
      "8               22.8          29.079083 -6.279083\n",
      "9               19.2          18.322931  0.877069\n",
      "10              17.8          20.026541 -2.226541\n",
      "11              16.4          13.204039  3.195961\n",
      "12              17.3          15.195904  2.104096\n",
      "13              15.2          15.899143 -0.699143\n",
      "14              10.4          13.011010 -2.611010\n",
      "15              10.4          11.176202 -0.776202\n",
      "16              14.7           8.633541  6.066459\n",
      "17              32.4          26.764896  5.635104\n",
      "18              30.4          29.366959  1.033041\n",
      "19              33.9          28.180208  5.719792\n",
      "20              21.5          25.282220 -3.782220\n",
      "21              15.5          17.345282 -1.845282\n",
      "22              15.2          18.267301 -3.067301\n",
      "23              13.3          13.310776 -0.010776\n",
      "24              19.2          16.042947  3.157053\n",
      "25              27.3          28.458222 -1.158222\n",
      "26              26.0          26.407484 -0.407484\n",
      "27              30.4          25.541415  4.858585\n",
      "28              15.8          24.917067 -9.117067\n",
      "29              19.7          19.689587  0.010413\n",
      "30              15.0          12.035015  2.964985\n",
      "31              21.4          25.584669 -4.184669\n",
      "R-Squared:  0.6538538719944074\n",
      "Adjusted R-Squared:  0.4890223824679346\n"
     ]
    }
   ],
   "source": [
    "# 1B\n",
    "LOOCV(X_, y_, a, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc48d3",
   "metadata": {},
   "source": [
    "##### We can see in this portion that the R-squared and adjusted R-squared values are worse than the previous model's and that the errors between observations are much higher than the previous model's as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36a842",
   "metadata": {},
   "source": [
    "### 1. (C) (Predict car mileage using MLR with k mean features and report R-squared values graphically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47a57ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1C\n",
    "k_feat_calc(X_, y_, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76594e9",
   "metadata": {},
   "source": [
    "##### We can see in this portion that the R-squared and adjusted R-squared increase with the addition of new features, but do not significantly change beyond the 5th feature's addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7180967",
   "metadata": {},
   "source": [
    "### Function for Cancer Predictions in Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "606c59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cancer(X, y, theta):\n",
    "    y_hat = []\n",
    "    threshold = 0.5\n",
    "    m = len(y)\n",
    "    for i in range(m):\n",
    "        p = -1 * (nump.dot(theta, nump.array(X[i])))\n",
    "        h_theta_x = (1 / (1 + math.exp(p)))\n",
    "        if h_theta_x <= threshold:  # if predictor is less than 0.5, we have class 0\n",
    "            y_hat.append(0)\n",
    "        else:\n",
    "            y_hat.append(1)\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    P = 0\n",
    "    N = 0\n",
    "    PP = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        # count our classifications\n",
    "        if y_hat[i] == y[i]:    # correct if match\n",
    "            if y_hat[i] == 1:   # TP if eq 1, else TN\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        if y[i] == 1:\n",
    "            P += 1\n",
    "        else:\n",
    "            N += 1\n",
    "        if y_hat[i] == 1:\n",
    "            PP += 1\n",
    "\n",
    "    confuse = pd.crosstab(y, y_hat, rownames=['Actual'], colnames=\n",
    "                          ['Predicted'], margins=True)\n",
    "    correct_class = (TP + TN) / m\n",
    "    precision = TP / PP\n",
    "    recall = TP / P\n",
    "    specificity = TN / N\n",
    "    f1 = 2 / (pow(precision, -1) + pow(recall, -1))\n",
    "\n",
    "    print(confuse)\n",
    "    print(\"Correct % of classifications:\\t\", correct_class)\n",
    "    print(\"Precision:\\t\", precision)\n",
    "    print(\"Recall:\\t\", recall)\n",
    "    print(\"Specificity:\\t\", specificity)\n",
    "    print(\"F1:\\t\", f1)\n",
    "    print(\"Odds Ratio:\\t\", math.exp(theta[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc5899",
   "metadata": {},
   "source": [
    "### 2. (A) (Learning logistic regression hypothesis for lung cancer as a function of smoking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc246c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22245295  0.62752791]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2\"\"\"\n",
    "# 2A\n",
    "X1, y1 = file_import2('cancer.csv')\n",
    "Thetas2, runtime2, costs2, iterations2 = gradient_descent(X1, y1, a, 'cancer')\n",
    "print(Thetas2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad22c3b",
   "metadata": {},
   "source": [
    "### 2. (B) (Classifying each individual as having lunger cancer or not, reporting the confusion matrix and other statistically significant results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99476ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0   1  All\n",
      "Actual               \n",
      "0          5   4    9\n",
      "1          4   6   10\n",
      "All        9  10   19\n",
      "Correct % of classifications:\t 0.5789473684210527\n",
      "Precision:\t 0.6\n",
      "Recall:\t 0.6\n",
      "Specificity:\t 0.5555555555555556\n",
      "F1:\t 0.6\n",
      "Odds Ratio:\t 1.8729746880712026\n"
     ]
    }
   ],
   "source": [
    "# 2B\n",
    "pred_cancer(X1, y1, Thetas2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c53c3d",
   "metadata": {},
   "source": [
    "##### We can see that the model is not too accurate in correctly classifying cancer predictions, but it is at least near 60% accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f14615",
   "metadata": {},
   "source": [
    "### 2. (C)\n",
    "\n",
    "##### Using the calculated Odds ratio, I think it can be determined that smokers are about 1.87 times as likely to develop cancer than non-smokers are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee16438",
   "metadata": {},
   "source": [
    "### Functions written to assist with Question 3's scaling and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40ed6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X):\n",
    "    X1 = pd.DataFrame(X)\n",
    "\n",
    "    X1 = X1.drop(0, axis='columns')\n",
    "    mean = X1.mean()    # save these for later\n",
    "    std = X1.std()\n",
    "    X1 = (X1 - X1.mean()) / X1.std()\n",
    "    X1.insert(0, 0, 1, True)\n",
    "    X1 = X1.values.tolist()\n",
    "\n",
    "    return X1, mean, std\n",
    "\n",
    "\n",
    "def scaling2(X, mean, std):\n",
    "    X = pd.DataFrame(X)\n",
    "    X = X.drop(0, axis='columns')\n",
    "    X = (X - mean) / std\n",
    "    X.insert(0, 0, 1, True)\n",
    "    X = X.values.tolist()\n",
    "    return X\n",
    "\n",
    "\n",
    "def pred_flower(X, y, theta):\n",
    "    y = y.tolist()\n",
    "    y = [j for sub in y for j in sub]\n",
    "    y_hat = []\n",
    "    m = len(y)\n",
    "\n",
    "    for i in range(m):\n",
    "        h_set = (1 / (1 + math.exp(-1 * (nump.dot(theta[0], X[i])))))\n",
    "        h_ver = (1 / (1 + math.exp(-1 * (nump.dot(theta[1], X[i])))))\n",
    "        h_vir = (1 / (1 + math.exp(-1 * (nump.dot(theta[2], X[i])))))\n",
    "        p = max(h_set, h_ver, h_vir)\n",
    "        if p == h_set:\n",
    "            y_hat.append('setosa')\n",
    "        elif p == h_ver:\n",
    "            y_hat.append('versicolor')\n",
    "        else:\n",
    "            y_hat.append('virginica')\n",
    "\n",
    "    T = 0\n",
    "    Set_T = 0\n",
    "    Ver_T = 0\n",
    "    Vir_T = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        # count our classifications\n",
    "        if y_hat[i] == y[i]:  # correct if match\n",
    "            T += 1\n",
    "            if y_hat[i] == 'setosa':\n",
    "                Set_T += 1\n",
    "            if y_hat[i] == 'versicolor':\n",
    "                Ver_T += 1\n",
    "            if y_hat[i] == 'virginica':\n",
    "                Vir_T += 1\n",
    "\n",
    "    confuse = pd.crosstab(y, y_hat, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    correct_class = T / m\n",
    "    Set_correct = Set_T / (m/3)\n",
    "    Ver_correct = Ver_T / (m/3)\n",
    "    Vir_correct = Vir_T / (m/3)\n",
    "\n",
    "    print(confuse)\n",
    "    print(\"Overall Correct % of Classifications:\\t\", correct_class)\n",
    "    print(\"Setosa Correct % of Classifications:\\t\", Set_correct)\n",
    "    print(\"Versicolor Correct % of Classifications:\\t\", Ver_correct)\n",
    "    print(\"Virginica Correct % of Classifications:\\t\", Vir_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d9bae",
   "metadata": {},
   "source": [
    "### 3. (A) (Separate data in training and test data using an 80-20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a42e0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"3\"\"\"\n",
    "# 3A - Divide into test and train data sets\n",
    "X2, y_f = file_import3('flowers.csv')\n",
    "y_1 = nump.transpose(nump.matrix([1 if val == 'setosa' else 0 for val in y_f]))\n",
    "y_2 = nump.transpose(nump.matrix([1 if val == 'versicolor' else 0 for val in y_f]))\n",
    "y_3 = nump.transpose(nump.matrix([1 if val == 'virginica' else 0 for val in y_f]))\n",
    "\n",
    "rows = [i for i in range(X2.shape[0])]\n",
    "trainRows = [i for i in range(0, 40)] + [i for i in range(50, 90)] + [i for i in range(100, 140)]\n",
    "testRows = sorted(list(set.difference(set(rows), set(trainRows))))\n",
    "\n",
    "XTrain = X2[trainRows, :]   # scale me\n",
    "yTrain = y_f[trainRows, :]\n",
    "\n",
    "y1Train = y_1[trainRows, :]\n",
    "y2Train = y_2[trainRows, :]\n",
    "y3Train = y_3[trainRows, :]\n",
    "\n",
    "XTest = X2[testRows, :]     # scale me with XTrain's mean and std\n",
    "yTest = y_f[testRows, :]\n",
    "\n",
    "y1Test = y_1[testRows, :]\n",
    "y2Test = y_2[testRows, :]\n",
    "y3Test = y_3[testRows, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cef21e",
   "metadata": {},
   "source": [
    "### 3. (B) (Scale the training data and the test data using the mean and variance from the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2082d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3B - Scaling\n",
    "XTrainScaled, X_mean, X_std = scaling(XTrain)\n",
    "XTestScaled = scaling2(XTest, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd89c6",
   "metadata": {},
   "source": [
    "### 3. (C) (Train the three different models using the training set to determine probabilites of a flower being in a particular species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e5e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.24334614 -1.75999339  3.9898382  -4.42729052 -4.45791134]\n",
      "[-0.94861559  0.27162912 -1.38605387  0.61796515 -0.89460269]\n",
      "[-18.70584143  -1.99562271  -2.78318499  15.79802893  12.91789495]\n"
     ]
    }
   ],
   "source": [
    "# 3C - Learn probabilities with 3 separate models for classification\n",
    "# model 1 (setosa)\n",
    "Thetas_s, runtime_s, costs_s, iterations_s = gradient_descent(XTrainScaled, y1Train, a, 'logistic')\n",
    "print(Thetas_s)\n",
    "\n",
    "# model 2 (versicolor)\n",
    "Thetas_versi, runtime_versi, costs_versi, iterations_versi = gradient_descent(XTrainScaled, y2Train, a, 'logistic')\n",
    "print(Thetas_versi)\n",
    "\n",
    "# model 3 (virginica)\n",
    "Thetas_virg, runtime_virg, costs_virg, iterations_virg = gradient_descent(XTrainScaled, y3Train, a, 'logistic')\n",
    "print(Thetas_virg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807f34e",
   "metadata": {},
   "source": [
    "### 3. (D) (Classify each flower from the training data set using the learned proabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "327964a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   setosa  versicolor  virginica  All\n",
      "Actual                                        \n",
      "setosa          40           0          0   40\n",
      "versicolor       0          38          2   40\n",
      "virginica        0           1         39   40\n",
      "All             40          39         41  120\n",
      "Overall Correct % of Classifications:\t 0.975\n",
      "Setosa Correct % of Classifications:\t 1.0\n",
      "Versicolor Correct % of Classifications:\t 0.95\n",
      "Virginica Correct % of Classifications:\t 0.975\n"
     ]
    }
   ],
   "source": [
    "# 3D - Predictions using training data\n",
    "pred_flower(XTrainScaled, yTrain, [Thetas_s, Thetas_versi, Thetas_virg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a9ecf",
   "metadata": {},
   "source": [
    "##### We can observe the model does very well in correctly classifying all the training data flowers based upon their species using the given features. Each species is correctly identified with the exception of 3 samples in the entire set of 120."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf4d71",
   "metadata": {},
   "source": [
    "### 3. (E) (Classify each flower from the testing data set using the learned proabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac5c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   setosa  versicolor  virginica  All\n",
      "Actual                                        \n",
      "setosa          10           0          0   10\n",
      "versicolor       0          10          0   10\n",
      "virginica        0           0         10   10\n",
      "All             10          10         10   30\n",
      "Overall Correct % of Classifications:\t 1.0\n",
      "Setosa Correct % of Classifications:\t 1.0\n",
      "Versicolor Correct % of Classifications:\t 1.0\n",
      "Virginica Correct % of Classifications:\t 1.0\n"
     ]
    }
   ],
   "source": [
    "# 3E - Predictions using test data\n",
    "pred_flower(XTestScaled, yTest, [Thetas_s, Thetas_versi, Thetas_virg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d6c34",
   "metadata": {},
   "source": [
    "##### We can observe the model does perfectly in classifying all the test data flowers based upon their species using the given features. Each species is correctly identified from the entire test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1d9df",
   "metadata": {},
   "source": [
    "### Extra Credit Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c878e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainScaled = pd.DataFrame(XTrainScaled)\n",
    "XTrainScaled = XTrainScaled.drop(1, axis='columns')\n",
    "XTrainScaled = XTrainScaled.values.tolist()\n",
    "\n",
    "# model 1 (setosa)\n",
    "Thetas_s1, runtime_s1, costs_s1, iterations_s1 = gradient_descent(XTrainScaled, y1Train, a, 'logistic')\n",
    "print(Thetas_s1)\n",
    "\n",
    "# model 2 (versicolor)\n",
    "Thetas_versi1, runtime_versi1, costs_versi1, iterations_versi1 = gradient_descent(XTrainScaled, y2Train, a, 'logistic')\n",
    "print(Thetas_versi1)\n",
    "\n",
    "# model 3 (virginica)\n",
    "Thetas_virg1, runtime_virg1, costs_virg1, iterations_virg1 = gradient_descent(XTrainScaled, y3Train, a, 'logistic')\n",
    "print(Thetas_virg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad752b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
